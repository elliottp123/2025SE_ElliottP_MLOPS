{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Student secondary school performance based on primary school performance in math or Portuguese\n",
        "\n",
        "**The scope and aim of this model is to:** use random forest models and linear regression averaging to find the relationship between student primary school performance and secondary school performance, using a range of features such as-\n",
        "\n",
        "## Attributes of our data\n",
        "\n",
        "| # | Attribute | Description | Type |\n",
        "|---|-----------|-------------|------|\n",
        "| 1 | school | Student's school ('GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) | Binary |\n",
        "| 2 | sex | Student's sex ('F' - female or 'M' - male) | Binary |\n",
        "| 3 | age | Student's age (from 15 to 22) | Numeric |\n",
        "| 4 | address | Student's home address type ('U' - urban or 'R' - rural) | Binary |\n",
        "| 5 | famsize | Family size ('LE3' - less or equal to 3 or 'GT3' - greater than 3) | Binary |\n",
        "| 6 | Pstatus | Parent's cohabitation status ('T' - living together or 'A' - apart) | Binary |\n",
        "| 7 | Medu | Mother's education (0 - none, 1 - primary education, 2 - 5th to 9th grade, 3 - secondary education, 4 - higher education) | Numeric |\n",
        "| 8 | Fedu | Father's education (0 - none, 1 - primary education, 2 - 5th to 9th grade, 3 - secondary education, 4 - higher education) | Numeric |\n",
        "| 9 | Mjob | Mother's job ('teacher', 'health' care, 'services', 'at_home', 'other') | Nominal |\n",
        "| 10 | Fjob | Father's job ('teacher', 'health' care, 'services', 'at_home', 'other') | Nominal |\n",
        "| 11 | reason | Reason to choose this school ('home', 'reputation', 'course', 'other') | Nominal |\n",
        "| 12 | guardian | Student's guardian ('mother', 'father', 'other') | Nominal |\n",
        "| 13 | traveltime | Home to school travel time (1 - <15 min, 2 - 15-30 min, 3 - 30-60 min, 4 - >1 hour) | Numeric |\n",
        "| 14 | studytime | Weekly study time (1 - <2 hours, 2 - 2-5 hours, 3 - 5-10 hours, 4 - >10 hours) | Numeric |\n",
        "| 15 | failures | Number of past class failures (n if 1<=n<3, else 4) | Numeric |\n",
        "| 16 | schoolsup | Extra educational support (yes or no) | Binary |\n",
        "| 17 | famsup | Family educational support (yes or no) | Binary |\n",
        "| 18 | paid | Extra paid classes (yes or no) | Binary |\n",
        "| 19 | activities | Extra-curricular activities (yes or no) | Binary |\n",
        "| 20 | nursery | Attended nursery school (yes or no) | Binary |\n",
        "| 21 | higher | Wants to take higher education (yes or no) | Binary |\n",
        "| 22 | internet | Internet access at home (yes or no) | Binary |\n",
        "| 23 | romantic | With a romantic relationship (yes or no) | Binary |\n",
        "| 24 | famrel | Quality of family relationships (from 1 - very bad to 5 - excellent) | Numeric |\n",
        "| 25 | freetime | Free time after school (from 1 - very low to 5 - very high) | Numeric |\n",
        "| 26 | goout | Going out with friends (from 1 - very low to 5 - very high) | Numeric |\n",
        "| 27 | Dalc | Workday alcohol consumption (from 1 - very low to 5 - very high) | Numeric |\n",
        "| 28 | Walc | Weekend alcohol consumption (from 1 - very low to 5 - very high) | Numeric |\n",
        "| 29 | health | Current health status (from 1 - very bad to 5 - very good) | Numeric |\n",
        "| 30 | absences | Number of school absences (from 0 to 93) | Numeric |\n",
        "\n",
        "### Grade-related attributes (target variables):\n",
        "| # | Attribute | Description | Type |\n",
        "|---|-----------|-------------|------|\n",
        "| 31 | G1 | First period grade (from 0 to 20) | Numeric |\n",
        "| 32 | G2 | Second period grade (from 0 to 20) | Numeric |\n",
        "| 33 | G3 | Final grade (from 0 to 20, output target) | Numeric |\n",
        "\n",
        "\n",
        "### (from these datasets)\n",
        "    > mat.arff // just the math results for G1-G3\n",
        "    > por.arff // just the portugese resutls for G1-G3\n",
        "    > dataset.csv // the \"combined\" data set of por and math results, without G1 or G2, with only G3 as target\n",
        "\n",
        "## Engineered features:\n",
        "\n",
        "| Feature | Description | Calculation |\n",
        "|---------|-------------|-------------|\n",
        "| Gvg | G1 and G2 average grade | Integer of (G1 + G2) / 2 |\n",
        "| Avgalc | Average alcohol consumption | Integer of (Dalc + Walc) / 2 |\n",
        "| Bum | Student's risk indicator | Weighted sum of failures, absences, Dalc, Walc, inverted studytime, and freetime |\n",
        "\n",
        "Implementing these engineered features along with out many attributes will allow us to use random forest classifiers on G1 and G2 as seperate models to find the classifications of a students primary school grades based on their lifestyles.\n",
        "And then a G3 linear regression model that factors in G1 and G2 to predict highschool results with full informed hindsight.\n",
        "Using this method allows us to analyse the importance of our features, while creating a layers and educated prediction of student rank."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import frameworks\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "from io import StringIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load ARFF files as CSV\n",
        "def load_arff_as_csv(filepath):\n",
        "    with open(filepath, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    data_start = False\n",
        "    data = []\n",
        "    for line in lines:\n",
        "        if data_start:\n",
        "            data.append(line.strip())\n",
        "        if line.strip().lower() == '@data':\n",
        "            data_start = True\n",
        "    return pd.read_csv(StringIO('\\n'.join(data)), header=None)\n",
        "\n",
        "# Load ARFF files\n",
        "mat_df = load_arff_as_csv('data/mat.arff')\n",
        "por_df = load_arff_as_csv('data/por.arff')\n",
        "\n",
        "# Set column names for mat.arff\n",
        "mat_columns = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n",
        "mat_df.columns = mat_columns\n",
        "\n",
        "# Set column names for por.arff\n",
        "por_columns = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n",
        "por_df.columns = por_columns\n",
        "\n",
        "# Load CSV file (which is actually in ARFF format)\n",
        "csv_columns = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G3']\n",
        "\n",
        "# Use the same ARFF loading function for dataset.csv\n",
        "csv_df = load_arff_as_csv('data/dataset.csv')\n",
        "csv_df.columns = csv_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Dealing with null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Removing them because they are not needed, and filling in produces lower accuracy\n",
        "def remove_nulls(df):\n",
        "    df = df.dropna()\n",
        "    return df\n",
        "\n",
        "mat_df = remove_nulls(mat_df)\n",
        "por_df = remove_nulls(por_df)\n",
        "csv_df = remove_nulls(csv_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Remove Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_duplicates(df):\n",
        "    df = df.drop_duplicates()\n",
        "    return df\n",
        "\n",
        "mat_df = remove_duplicates(mat_df)\n",
        "por_df = remove_duplicates(por_df)\n",
        "csv_df = remove_duplicates(csv_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Replace data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def replace_data(df, column):\n",
        "    df[column] = df[column].apply(lambda x: x.lower())\n",
        "    return df\n",
        "\n",
        "mat_df = replace_data(mat_df, 'sex')\n",
        "por_df = replace_data(por_df, 'sex')\n",
        "csv_df = replace_data(csv_df, 'sex')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Remove outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outlier removal statistics:\n",
            "  • age: removed 1 outliers (bounds: 13.00 to 21.00)\n",
            "  • absences: removed 15 outliers (bounds: -12.00 to 20.00)\n",
            "  • G1: removed 0 outliers (bounds: 0.50 to 20.50)\n",
            "  • G2: removed 13 outliers (bounds: 3.00 to 19.00)\n",
            "  • G3: removed 25 outliers (bounds: 1.50 to 21.50)\n",
            "  • studytime: removed 24 outliers (bounds: -0.50 to 3.50)\n",
            "  • failures: removed 54 outliers (bounds: 0.00 to 0.00)\n",
            "  • Dalc: removed 12 outliers (bounds: -0.50 to 3.50)\n",
            "  • Walc: removed 0 outliers (bounds: -2.00 to 6.00)\n",
            "Total: 144 rows removed out of 395 (36.46%)\n",
            "Outlier removal statistics:\n",
            "  • age: removed 1 outliers (bounds: 13.00 to 21.00)\n",
            "  • absences: removed 21 outliers (bounds: -9.00 to 15.00)\n",
            "  • G1: removed 16 outliers (bounds: 5.50 to 17.50)\n",
            "  • G2: removed 15 outliers (bounds: 5.50 to 17.50)\n",
            "  • G3: removed 7 outliers (bounds: 4.00 to 20.00)\n",
            "  • studytime: removed 31 outliers (bounds: -0.50 to 3.50)\n",
            "  • failures: removed 78 outliers (bounds: 0.00 to 0.00)\n",
            "  • Dalc: removed 19 outliers (bounds: -0.50 to 3.50)\n",
            "  • Walc: removed 0 outliers (bounds: -2.00 to 6.00)\n",
            "Total: 188 rows removed out of 649 (28.97%)\n",
            "Outlier removal statistics:\n",
            "  • age: removed 1 outliers (bounds: 13.00 to 21.00)\n",
            "  • absences: removed 21 outliers (bounds: -9.00 to 15.00)\n",
            "  • G3: removed 16 outliers (bounds: 4.00 to 20.00)\n",
            "  • studytime: removed 35 outliers (bounds: -0.50 to 3.50)\n",
            "  • failures: removed 81 outliers (bounds: 0.00 to 0.00)\n",
            "  • Dalc: removed 19 outliers (bounds: -0.50 to 3.50)\n",
            "  • Walc: removed 0 outliers (bounds: -2.00 to 6.00)\n",
            "Total: 173 rows removed out of 649 (26.66%)\n"
          ]
        }
      ],
      "source": [
        "# Remove outliers using IQR method across multiple columns\n",
        "def remove_outliers(df, columns_to_check=['age', 'absences', 'G1', 'G2', 'G3']):\n",
        "    df_clean = df.copy()\n",
        "    original_rows = len(df_clean)\n",
        "    \n",
        "    print(\"Outlier removal statistics:\")\n",
        "    for col in columns_to_check:\n",
        "        if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
        "            # Calculate IQR\n",
        "            Q1 = df_clean[col].quantile(0.25)\n",
        "            Q3 = df_clean[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            \n",
        "            # Define bounds\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            \n",
        "            # Count outliers before removal\n",
        "            outliers_count = df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)].shape[0]\n",
        "            \n",
        "            # Remove outliers\n",
        "            df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
        "            \n",
        "            # Print statistics\n",
        "            print(f\"  • {col}: removed {outliers_count} outliers (bounds: {lower_bound:.2f} to {upper_bound:.2f})\")\n",
        "    \n",
        "    # Print summary\n",
        "    rows_removed = original_rows - len(df_clean)\n",
        "    print(f\"Total: {rows_removed} rows removed out of {original_rows} ({rows_removed/original_rows*100:.2f}%)\")\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "# Apply enhanced outlier detection to all datasets\n",
        "numerical_columns = ['age', 'absences', 'G1', 'G2', 'G3', 'studytime', 'failures', 'Dalc', 'Walc']\n",
        "mat_df = remove_outliers(mat_df, numerical_columns)\n",
        "por_df = remove_outliers(por_df, numerical_columns)\n",
        "csv_df = remove_outliers(csv_df, numerical_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Scaling features to a common range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Applying feature scaling:\n",
            "Scaled features: age, Medu, Fedu, traveltime, studytime, failures, famrel, freetime, goout, Dalc, Walc, health, absences\n",
            "Scaled features: age, Medu, Fedu, traveltime, studytime, failures, famrel, freetime, goout, Dalc, Walc, health, absences\n",
            "Scaled features: age, Medu, Fedu, traveltime, studytime, failures, famrel, freetime, goout, Dalc, Walc, health, absences\n"
          ]
        }
      ],
      "source": [
        "# Scale numerical features to a common range [0,1]\n",
        "def scale_features(df, columns_to_scale):\n",
        "    df_scaled = df.copy()\n",
        "    \n",
        "    # Filter only existing numerical columns\n",
        "    valid_columns = [col for col in columns_to_scale \n",
        "                    if col in df.columns and pd.api.types.is_numeric_dtype(df[col])]\n",
        "    \n",
        "    if valid_columns:\n",
        "        # Apply scaling\n",
        "        scaler = MinMaxScaler()\n",
        "        df_scaled[valid_columns] = scaler.fit_transform(df[valid_columns])\n",
        "        print(f\"Scaled features: {', '.join(valid_columns)}\")\n",
        "    \n",
        "    return df_scaled\n",
        "\n",
        "# Define which numerical columns should be scaled, excluding categorical ones\n",
        "numerical_features = [\n",
        "    'age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures',\n",
        "    'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences'\n",
        "]\n",
        "\n",
        "# Apply scaling to all datasets\n",
        "print(\"\\nApplying feature scaling:\")\n",
        "mat_df = scale_features(mat_df, numerical_features)\n",
        "por_df = scale_features(por_df, numerical_features)\n",
        "csv_df = scale_features(csv_df, numerical_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save the wrangled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create directory if it doesn't exist\n",
        "os.makedirs('processed_data', exist_ok=True)\n",
        "\n",
        "# Save the processed data files\n",
        "mat_df.to_csv('processed_data/Pmat_full.csv', index=False)\n",
        "por_df.to_csv('processed_data/Ppor_full.csv', index=False)\n",
        "csv_df.to_csv('processed_data/Pdataset.csv', index=False)\n",
        "# Raw processed data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split by gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outlier removal statistics:\n",
            "Total: 0 rows removed out of 251 (0.00%)\n",
            "Unique values in sex column (Math): [\"'f'\" \"'m'\"]\n",
            "Outlier removal statistics:\n",
            "Total: 0 rows removed out of 461 (0.00%)\n",
            "Unique values in sex column (Portuguese): [\"'f'\" \"'m'\"]\n",
            "\n",
            "Gender Distribution after Outlier Removal:\n",
            "\n",
            "Mathematics Dataset:\n",
            "Female: 132 (52.6%)\n",
            "Male: 119 (47.4%)\n",
            "\n",
            "Portuguese Dataset:\n",
            "Female: 282 (61.2%)\n",
            "Male: 179 (38.8%)\n",
            "\n",
            "Files saved in processed_data folder\n"
          ]
        }
      ],
      "source": [
        "# Create processed_data directory if it doesn't exist\n",
        "os.makedirs('processed_data', exist_ok=True)\n",
        "\n",
        "# Process Mathematics data\n",
        "mat_df = remove_outliers(mat_df, 'age')\n",
        "# Check unique values in sex column\n",
        "print(\"Unique values in sex column (Math):\", mat_df['sex'].unique())\n",
        "PmatFE = mat_df[mat_df['sex'].str.contains('F', case=False)].copy()\n",
        "PmatM = mat_df[mat_df['sex'].str.contains('M', case=False)].copy()\n",
        "\n",
        "# Process Portuguese data\n",
        "por_df = remove_outliers(por_df, 'age')\n",
        "print(\"Unique values in sex column (Portuguese):\", por_df['sex'].unique())\n",
        "PporFE = por_df[por_df['sex'].str.contains('F', case=False)].copy()\n",
        "PporM = por_df[por_df['sex'].str.contains('M', case=False)].copy()\n",
        "\n",
        "# Save gender-split datasets\n",
        "PmatFE.to_csv('processed_data/PmatFE.csv', index=False)\n",
        "PmatM.to_csv('processed_data/PmatM.csv', index=False)\n",
        "PporFE.to_csv('processed_data/PporFE.csv', index=False)\n",
        "PporM.to_csv('processed_data/PporM.csv', index=False)\n",
        "\n",
        "# Print verification statistics\n",
        "print(\"\\nGender Distribution after Outlier Removal:\")\n",
        "print(\"\\nMathematics Dataset:\")\n",
        "print(f\"Female: {len(PmatFE)} ({len(PmatFE)/len(mat_df)*100:.1f}%)\")\n",
        "print(f\"Male: {len(PmatM)} ({len(PmatM)/len(mat_df)*100:.1f}%)\")\n",
        "print(\"\\nPortuguese Dataset:\")\n",
        "print(f\"Female: {len(PporFE)} ({len(PporFE)/len(por_df)*100:.1f}%)\")\n",
        "print(f\"Male: {len(PporM)} ({len(PporM)/len(por_df)*100:.1f}%)\")\n",
        "print(\"\\nFiles saved in processed_data folder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split data for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing and saving train-test splits...\n",
            "\n",
            "PmatFE:\n",
            "Training: 105 samples\n",
            "Testing: 27 samples\n",
            "\n",
            "PmatM:\n",
            "Training: 95 samples\n",
            "Testing: 24 samples\n",
            "\n",
            "PporFE:\n",
            "Training: 225 samples\n",
            "Testing: 57 samples\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 5, got 4)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[50], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m X_train_mat_m, X_test_mat_m, y_train_mat_m, y_test_mat_m \u001b[38;5;241m=\u001b[39m split_save_and_print(PmatM, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPmatM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Portuguese splits\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m X_train_por_f,X_train_por_f, X_test_por_f, y_train_por_f, y_test_por_f \u001b[38;5;241m=\u001b[39m split_save_and_print(PporFE, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPporFE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m X_train_por_m, X_test_por_m, y_train_por_m, y_test_por_m \u001b[38;5;241m=\u001b[39m split_save_and_print(PporM, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPporM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll splits have been saved to the processed_data folder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
          ]
        }
      ],
      "source": [
        "# Function to split and save datasets\n",
        "def split_save_and_print(data, name, test_size=0.2, random_state=42):\n",
        "    X = data.drop(['sex', 'G1', 'G2', 'G3'], axis=1)\n",
        "    y = data[['G1', 'G2', 'G3']]\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    \n",
        "    # Save splits with new naming convention\n",
        "    base_path = 'processed_data'\n",
        "    X_train.to_csv(f'{base_path}/X_{name}_train.csv', index=False)\n",
        "    X_test.to_csv(f'{base_path}/X_{name}_test.csv', index=False)\n",
        "    y_train.to_csv(f'{base_path}/Y_{name}_train.csv', index=False)\n",
        "    y_test.to_csv(f'{base_path}/Y_{name}_test.csv', index=False)\n",
        "    \n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"Training: {X_train.shape[0]} samples\")\n",
        "    print(f\"Testing: {X_test.shape[0]} samples\")\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "print(\"Performing and saving train-test splits...\")\n",
        "\n",
        "# Mathematics splits\n",
        "X_train_mat_f, X_test_mat_f, y_train_mat_f, y_test_mat_f = split_save_and_print(PmatFE, \"PmatFE\")\n",
        "X_train_mat_m, X_test_mat_m, y_train_mat_m, y_test_mat_m = split_save_and_print(PmatM, \"PmatM\")\n",
        "\n",
        "# Portuguese splits\n",
        "X_train_por_f,X_train_por_f, X_test_por_f, y_train_por_f, y_test_por_f = split_save_and_print(PporFE, \"PporFE\")\n",
        "X_train_por_m, X_test_por_m, y_train_por_m, y_test_por_m = split_save_and_print(PporM, \"PporM\")\n",
        "\n",
        "print(\"\\nAll splits have been saved to the processed_data folder\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
