{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n",
        "\n",
        "### Engineered Features and Justifications\n",
        "\n",
        "1. **Gvg** - G1 and G2 average grade (integer of (G1 + G2) / 2)\n",
        "   - Justification: Averaging the first and second period grades provides a more stable measure of a student's performance over time, reducing the impact of any single period's anomalies.\n",
        "\n",
        "2. **Avgalc** - Average Dalc and Walc (integer of (Dalc + Walc) / 2)\n",
        "   - Justification: Combining workday and weekend alcohol consumption into a single average value gives a more comprehensive view of a student's overall alcohol consumption habits.\n",
        "\n",
        "3. **Bum** - A weighted sum of failures, absences, Dalc, Walc, inverted studytime, and freetime to indicate a student's tendency to fail, skip school, drink alcohol, not study, and have free time.\n",
        "   - Justification for weights:\n",
        "     - Failures are given a higher weight (2) because past class failures are a strong indicator of academic struggles.\n",
        "     - Absences are weighted at 1.5 as frequent absences can significantly impact academic performance.\n",
        "     - Both Dalc and Walc are weighted at 1 as alcohol consumption can affect both health and academic performance.\n",
        "     - Studytime is inverted (5 - studytime) and weighted at 1 because less study time can lead to poorer academic outcomes.\n",
        "     - Freetime is weighted at 1 as more free time might indicate less focus on academics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import dependancies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets loaded successfully:\n",
            "Mat: 394 rows, 33 columns\n",
            "Por: 648 rows, 33 columns\n"
          ]
        }
      ],
      "source": [
        "def load_datasets():\n",
        "    base_path = 'processed_data/'\n",
        "    datasets = {}\n",
        "    \n",
        "    try:\n",
        "        # Load full datasets\n",
        "        datasets['Mat'] = pd.read_csv(f'{base_path}Pmat_full.csv')\n",
        "        datasets['Por'] = pd.read_csv(f'{base_path}Ppor_full.csv')\n",
        "        \n",
        "        print(\"Datasets loaded successfully:\")\n",
        "        for name, df in datasets.items():\n",
        "            print(f\"{name}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "        \n",
        "        return datasets\n",
        "        \n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error loading datasets: {e}\")\n",
        "        return None\n",
        "\n",
        "# Load all datasets\n",
        "datasets = load_datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Calculating new features from existing features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_features(df):\n",
        "    \"\"\"Add engineered features to dataframe\"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Calculate grade average if G1 and G2 exist\n",
        "    if 'G1' in df.columns and 'G2' in df.columns:\n",
        "        df['Gvg'] = (df['G1'].astype(float) + df['G2'].astype(float)) / 2\n",
        "    \n",
        "    # Calculate alcohol average\n",
        "    df['Avgalc'] = (df['Dalc'].astype(float) + df['Walc'].astype(float)) / 2\n",
        "    \n",
        "    # Calculate risk factor (Bum)\n",
        "    df['Bum'] = (2.0 * df['failures'].astype(float) + \n",
        "                 1.5 * df['absences'].astype(float) + \n",
        "                 1.0 * df['Dalc'].astype(float) + \n",
        "                 1.0 * df['Walc'].astype(float) + \n",
        "                 1.0 * (5 - df['studytime'].astype(float)) + \n",
        "                 1.0 * df['freetime'].astype(float))\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing Mat dataset...\n",
            "Saved enhanced datasets for Mat\n",
            "\n",
            "Processing Por dataset...\n",
            "Saved enhanced datasets for Por\n"
          ]
        }
      ],
      "source": [
        "def process_and_save_datasets(datasets):\n",
        "    base_path = 'processed_data/'\n",
        "    processed_datasets = {}\n",
        "    \n",
        "    for name, df in datasets.items():\n",
        "        print(f\"\\nProcessing {name} dataset...\")\n",
        "        try:\n",
        "            # Add engineered features\n",
        "            processed_df = calculate_features(df)\n",
        "            \n",
        "            # Split by gender\n",
        "            processed_df_fe = processed_df[processed_df['sex'] == \"'f'\"].copy()\n",
        "            processed_df_m = processed_df[processed_df['sex'] == \"'m'\"].copy()\n",
        "            \n",
        "            # Save enhanced gender-split datasets\n",
        "            processed_df_fe.to_csv(f'{base_path}X_{name}FE_enhanced.csv', index=False)\n",
        "            processed_df_m.to_csv(f'{base_path}X_{name}M_enhanced.csv', index=False)\n",
        "            \n",
        "            # Store both gender splits in processed_datasets\n",
        "            processed_datasets[f'{name}FE'] = processed_df_fe\n",
        "            processed_datasets[f'{name}M'] = processed_df_m\n",
        "            \n",
        "            print(f\"Saved enhanced datasets for {name}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {name} dataset: {e}\")\n",
        "            continue\n",
        "    \n",
        "    return processed_datasets\n",
        "\n",
        "# Process all datasets\n",
        "if datasets:\n",
        "    processed_datasets = process_and_save_datasets(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyse features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Feature Engineering Statistics:\n",
            "\n",
            "MatFE Dataset Statistics:\n",
            "\n",
            "Gvg:\n",
            "  Mean: nan\n",
            "  Std: nan\n",
            "  Min: nan\n",
            "  Max: nan\n",
            "\n",
            "Avgalc:\n",
            "  Mean: nan\n",
            "  Std: nan\n",
            "  Min: nan\n",
            "  Max: nan\n",
            "\n",
            "Bum:\n",
            "  Mean: nan\n",
            "  Std: nan\n",
            "  Min: nan\n",
            "  Max: nan\n",
            "\n",
            "MatM Dataset Statistics:\n",
            "\n",
            "Gvg:\n",
            "  Mean: nan\n",
            "  Std: nan\n",
            "  Min: nan\n",
            "  Max: nan\n",
            "\n",
            "Avgalc:\n",
            "  Mean: nan\n",
            "  Std: nan\n",
            "  Min: nan\n",
            "  Max: nan\n",
            "\n",
            "Bum:\n",
            "  Mean: nan\n",
            "  Std: nan\n",
            "  Min: nan\n",
            "  Max: nan\n",
            "\n",
            "PorFE Dataset Statistics:\n",
            "\n",
            "Gvg:\n",
            "  Mean: nan\n",
            "  Std: nan\n",
            "  Min: nan\n",
            "  Max: nan\n",
            "\n",
            "Avgalc:\n",
            "  Mean: nan\n",
            "  Std: nan\n",
            "  Min: nan\n",
            "  Max: nan\n",
            "\n",
            "Bum:\n",
            "  Mean: nan\n",
            "  Std: nan\n",
            "  Min: nan\n",
            "  Max: nan\n",
            "\n",
            "PorM Dataset Statistics:\n",
            "\n",
            "Gvg:\n",
            "  Mean: nan\n",
            "  Std: nan\n",
            "  Min: nan\n",
            "  Max: nan\n",
            "\n",
            "Avgalc:\n",
            "  Mean: nan\n",
            "  Std: nan\n",
            "  Min: nan\n",
            "  Max: nan\n",
            "\n",
            "Bum:\n",
            "  Mean: nan\n",
            "  Std: nan\n",
            "  Min: nan\n",
            "  Max: nan\n"
          ]
        }
      ],
      "source": [
        "def analyze_features(processed_datasets):\n",
        "    print(\"\\nFeature Engineering Statistics:\")\n",
        "    \n",
        "    for name, df in processed_datasets.items():\n",
        "        print(f\"\\n{name} Dataset Statistics:\")\n",
        "        \n",
        "        new_features = ['Gvg', 'Avgalc', 'Bum']\n",
        "        for feature in new_features:\n",
        "            if feature in df.columns:\n",
        "                print(f\"\\n{feature}:\")\n",
        "                print(f\"  Mean: {df[feature].mean():.2f}\")\n",
        "                print(f\"  Std: {df[feature].std():.2f}\")\n",
        "                print(f\"  Min: {df[feature].min():.2f}\")\n",
        "                print(f\"  Max: {df[feature].max():.2f}\")\n",
        "            else:\n",
        "                print(f\"\\n{feature}: Not available for this dataset\")\n",
        "\n",
        "# Analyze all processed datasets\n",
        "if 'processed_datasets' in locals():\n",
        "    analyze_features(processed_datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Splitting and saving this data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing MatFE dataset for train-test split...\n",
            "Unique sex values in dataset: []\n",
            "Female samples: 0\n",
            "Male samples: 0\n",
            "\n",
            "Warning: MatFE dataset is empty, skipping split\n",
            "\n",
            "Processing MatM dataset for train-test split...\n",
            "Unique sex values in dataset: []\n",
            "Female samples: 0\n",
            "Male samples: 0\n",
            "\n",
            "Warning: MatM dataset is empty, skipping split\n",
            "\n",
            "Processing PorFE dataset for train-test split...\n",
            "Unique sex values in dataset: []\n",
            "Female samples: 0\n",
            "Male samples: 0\n",
            "\n",
            "Warning: PorFE dataset is empty, skipping split\n",
            "\n",
            "Processing PorM dataset for train-test split...\n",
            "Unique sex values in dataset: []\n",
            "Female samples: 0\n",
            "Male samples: 0\n",
            "\n",
            "Warning: PorM dataset is empty, skipping split\n"
          ]
        }
      ],
      "source": [
        "# Function to split and save datasets\n",
        "def split_save_and_print(data, name, test_size=0.3, random_state=42):\n",
        "    if len(data) == 0:\n",
        "        print(f\"\\nWarning: {name} dataset is empty, skipping split\")\n",
        "        return None, None, None, None\n",
        "        \n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        data.drop(['G1', 'G2', 'G3'], axis=1),\n",
        "        data[['G1', 'G2', 'G3']],\n",
        "        test_size=test_size,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    \n",
        "    # Save splits\n",
        "    base_path = f'processed_data/{name.lower().replace(\" \", \"_\")}'\n",
        "    X_train.to_csv(f'{base_path}_X_train.csv', index=False)\n",
        "    X_test.to_csv(f'{base_path}_X_test.csv', index=False)\n",
        "    y_train.to_csv(f'{base_path}_y_train.csv', index=False)\n",
        "    y_test.to_csv(f'{base_path}_y_test.csv', index=False)\n",
        "    \n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"Training: {X_train.shape[0]} samples\")\n",
        "    print(f\"Testing: {X_test.shape[0]} samples\")\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Process and save datasets\n",
        "if 'processed_datasets' in locals():\n",
        "    for name, df in processed_datasets.items():\n",
        "        print(f\"\\nProcessing {name} dataset for train-test split...\")\n",
        "        print(f\"Unique sex values in dataset: {df['sex'].unique()}\")\n",
        "        \n",
        "        # Split by gender using encoded values\n",
        "        df_female = df[df['sex'] == \"'f'\"].copy()\n",
        "        df_male = df[df['sex'] == \"'m'\"].copy()\n",
        "        \n",
        "        print(f\"Female samples: {len(df_female)}\")\n",
        "        print(f\"Male samples: {len(df_male)}\")\n",
        "        \n",
        "        if len(df_female) > 0:\n",
        "            # Split and save female datasets\n",
        "            split_save_and_print(df_female, f\"{name}FE\")\n",
        "        \n",
        "        if len(df_male) > 0:\n",
        "            # Split and save male datasets\n",
        "            split_save_and_print(df_male, f\"{name}M\")\n",
        "        \n",
        "        # Split and save full datasets\n",
        "        split_save_and_print(df, name)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
