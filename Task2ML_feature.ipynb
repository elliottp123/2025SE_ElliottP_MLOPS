{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n",
        "\n",
        "### Engineered Features and Justifications\n",
        "\n",
        "1. **Gvg** - G1 and G2 average grade (integer of (G1 + G2) / 2)\n",
        "   - Justification: Averaging the first and second period grades provides a more stable measure of a student's performance over time, reducing the impact of any single period's anomalies.\n",
        "\n",
        "2. **Avgalc** - Average Dalc and Walc (integer of (Dalc + Walc) / 2)\n",
        "   - Justification: Combining workday and weekend alcohol consumption into a single average value gives a more comprehensive view of a student's overall alcohol consumption habits.\n",
        "\n",
        "3. **Bum** - A weighted sum of failures, absences, Dalc, Walc, inverted studytime, and freetime to indicate a student's tendency to fail, skip school, drink alcohol, not study, and have free time.\n",
        "   - Justification for weights:\n",
        "     - Failures are given a higher weight (2) because past class failures are a strong indicator of academic struggles.\n",
        "     - Absences are weighted at 1.5 as frequent absences can significantly impact academic performance.\n",
        "     - Both Dalc and Walc are weighted at 1 as alcohol consumption can affect both health and academic performance.\n",
        "     - Studytime is inverted (5 - studytime) and weighted at 1 because less study time can lead to poorer academic outcomes.\n",
        "     - Freetime is weighted at 1 as more free time might indicate less focus on academics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import dependancies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets loaded successfully:\n",
            "MatFE: 208 rows, 33 columns\n",
            "MatM: 186 rows, 33 columns\n",
            "PorFE: 383 rows, 33 columns\n",
            "PorM: 265 rows, 33 columns\n"
          ]
        }
      ],
      "source": [
        "def load_datasets():\n",
        "    base_path = './processed_data/'\n",
        "    datasets = {}\n",
        "    \n",
        "    try:\n",
        "        # Load Mathematics datasets\n",
        "        datasets['MatFE'] = pd.read_csv(f'{base_path}PmatFE_full.csv')\n",
        "        datasets['MatM'] = pd.read_csv(f'{base_path}PmatM_full.csv')\n",
        "        \n",
        "        # Load Portuguese datasets\n",
        "        datasets['PorFE'] = pd.read_csv(f'{base_path}PporFE_full.csv')\n",
        "        datasets['PorM'] = pd.read_csv(f'{base_path}PporM_full.csv')\n",
        "        \n",
        "        print(\"Datasets loaded successfully:\")\n",
        "        for name, df in datasets.items():\n",
        "            print(f\"{name}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "        \n",
        "        return datasets\n",
        "        \n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error loading datasets: {e}\")\n",
        "        return None\n",
        "\n",
        "# Load all datasets\n",
        "datasets = load_datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Calculating new features from existing features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_features(df):\n",
        "    \"\"\"Add engineered features to dataframe\"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Calculate grade average if G1 and G2 exist\n",
        "    if 'G1' in df.columns and 'G2' in df.columns:\n",
        "        df['Gvg'] = (df['G1'].astype(float) + df['G2'].astype(float)) / 2\n",
        "    \n",
        "    # Calculate alcohol average\n",
        "    df['Avgalc'] = (df['Dalc'].astype(float) + df['Walc'].astype(float)) / 2\n",
        "    \n",
        "    # Calculate risk factor (Bum)\n",
        "    df['Bum'] = (2.0 * df['failures'].astype(float) + \n",
        "                 1.5 * df['absences'].astype(float) + \n",
        "                 1.0 * df['Dalc'].astype(float) + \n",
        "                 1.0 * df['Walc'].astype(float) + \n",
        "                 1.0 * (5 - df['studytime'].astype(float)) + \n",
        "                 1.0 * df['freetime'].astype(float))\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing MatFE dataset...\n",
            "Saved enhanced dataset to: ./processed_data/X_MatFE_enhanced.csv\n",
            "\n",
            "Processing MatM dataset...\n",
            "Saved enhanced dataset to: ./processed_data/X_MatM_enhanced.csv\n",
            "\n",
            "Processing PorFE dataset...\n",
            "Saved enhanced dataset to: ./processed_data/X_PorFE_enhanced.csv\n",
            "\n",
            "Processing PorM dataset...\n",
            "Saved enhanced dataset to: ./processed_data/X_PorM_enhanced.csv\n"
          ]
        }
      ],
      "source": [
        "def process_and_save_datasets(datasets):\n",
        "    base_path = './processed_data/'\n",
        "    processed_datasets = {}\n",
        "    \n",
        "    for name, df in datasets.items():\n",
        "        print(f\"\\nProcessing {name} dataset...\")\n",
        "        try:\n",
        "            # Add engineered features\n",
        "            processed_df = calculate_features(df)\n",
        "            \n",
        "            # Save enhanced dataset\n",
        "            output_file = f'{base_path}X_{name}_enhanced.csv'\n",
        "            processed_df.to_csv(output_file, index=False)\n",
        "            print(f\"Saved enhanced dataset to: {output_file}\")\n",
        "            \n",
        "            processed_datasets[name] = processed_df\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {name} dataset: {e}\")\n",
        "            continue\n",
        "    \n",
        "    return processed_datasets\n",
        "\n",
        "# Process all datasets\n",
        "if datasets:\n",
        "    processed_datasets = process_and_save_datasets(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyse features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Feature Engineering Statistics:\n",
            "\n",
            "MatFE Dataset Statistics:\n",
            "\n",
            "Gvg:\n",
            "  Mean: 10.50\n",
            "  Std: 3.30\n",
            "  Min: 2.00\n",
            "  Max: 18.50\n",
            "\n",
            "Avgalc:\n",
            "  Mean: 1.61\n",
            "  Std: 0.73\n",
            "  Min: 1.00\n",
            "  Max: 5.00\n",
            "\n",
            "Bum:\n",
            "  Mean: 18.87\n",
            "  Std: 14.70\n",
            "  Min: 6.00\n",
            "  Max: 118.50\n",
            "\n",
            "MatM Dataset Statistics:\n",
            "\n",
            "Gvg:\n",
            "  Mean: 11.17\n",
            "  Std: 3.50\n",
            "  Min: 2.50\n",
            "  Max: 19.00\n",
            "\n",
            "Avgalc:\n",
            "  Mean: 2.18\n",
            "  Std: 1.13\n",
            "  Min: 1.00\n",
            "  Max: 5.00\n",
            "\n",
            "Bum:\n",
            "  Mean: 19.42\n",
            "  Std: 10.16\n",
            "  Min: 5.00\n",
            "  Max: 68.00\n",
            "\n",
            "PorFE Dataset Statistics:\n",
            "\n",
            "Gvg:\n",
            "  Mean: 11.73\n",
            "  Std: 2.78\n",
            "  Min: 2.50\n",
            "  Max: 18.50\n",
            "\n",
            "Avgalc:\n",
            "  Mean: 1.61\n",
            "  Std: 0.74\n",
            "  Min: 1.00\n",
            "  Max: 5.00\n",
            "\n",
            "Bum:\n",
            "  Mean: 14.94\n",
            "  Std: 7.69\n",
            "  Min: 4.00\n",
            "  Max: 59.00\n",
            "\n",
            "PorM Dataset Statistics:\n",
            "\n",
            "Gvg:\n",
            "  Mean: 11.15\n",
            "  Std: 2.63\n",
            "  Min: 2.00\n",
            "  Max: 18.00\n",
            "\n",
            "Avgalc:\n",
            "  Mean: 2.28\n",
            "  Std: 1.16\n",
            "  Min: 1.00\n",
            "  Max: 5.00\n",
            "\n",
            "Bum:\n",
            "  Mean: 17.35\n",
            "  Std: 8.41\n",
            "  Min: 6.00\n",
            "  Max: 53.00\n"
          ]
        }
      ],
      "source": [
        "def analyze_features(processed_datasets):\n",
        "    print(\"\\nFeature Engineering Statistics:\")\n",
        "    \n",
        "    for name, df in processed_datasets.items():\n",
        "        print(f\"\\n{name} Dataset Statistics:\")\n",
        "        \n",
        "        new_features = ['Gvg', 'Avgalc', 'Bum']\n",
        "        for feature in new_features:\n",
        "            if feature in df.columns:\n",
        "                print(f\"\\n{feature}:\")\n",
        "                print(f\"  Mean: {df[feature].mean():.2f}\")\n",
        "                print(f\"  Std: {df[feature].std():.2f}\")\n",
        "                print(f\"  Min: {df[feature].min():.2f}\")\n",
        "                print(f\"  Max: {df[feature].max():.2f}\")\n",
        "            else:\n",
        "                print(f\"\\n{feature}: Not available for this dataset\")\n",
        "\n",
        "# Analyze all processed datasets\n",
        "if 'processed_datasets' in locals():\n",
        "    analyze_features(processed_datasets)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
