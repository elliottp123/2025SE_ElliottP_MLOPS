{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Testing\n",
        "\n",
        "This notebook loads the trained models, makes predictions, and evaluates the performance of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load test data and models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load test data\n",
        "def load_test_data():\n",
        "    base_path = 'processed_data/'\n",
        "    \n",
        "    # Load test data\n",
        "    X_test_mat_f = pd.read_csv(f'{base_path}matfe_X_test.csv')\n",
        "    y_test_mat_f = pd.read_csv(f'{base_path}matfe_y_test.csv')\n",
        "    X_test_mat_m = pd.read_csv(f'{base_path}matm_X_test.csv')\n",
        "    y_test_mat_m = pd.read_csv(f'{base_path}matm_y_test.csv')\n",
        "    \n",
        "    return X_test_mat_f, y_test_mat_f, X_test_mat_m, y_test_mat_m\n",
        "\n",
        "# Load models\n",
        "models = {\n",
        "    'g1_female': joblib.load('models/dt_g1_female.joblib'),\n",
        "    'g1_male': joblib.load('models/dt_g1_male.joblib'),\n",
        "    'g2_female': joblib.load('models/dt_g2_female.joblib'),\n",
        "    'g2_male': joblib.load('models/dt_g2_male.joblib'),\n",
        "    'g3_female': joblib.load('models/lr_g3_female.joblib'),\n",
        "    'g3_male': joblib.load('models/lr_g3_male.joblib')\n",
        "}\n",
        "\n",
        "# Load test data\n",
        "X_test_mat_f, y_test_mat_f, X_test_mat_m, y_test_mat_m = load_test_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions for G1 and G2\n",
        "y_pred_g1_f = models['g1_female'].predict(X_test_mat_f)\n",
        "y_pred_g1_m = models['g1_male'].predict(X_test_mat_m)\n",
        "y_pred_g2_f = models['g2_female'].predict(X_test_mat_f)\n",
        "y_pred_g2_m = models['g2_male'].predict(X_test_mat_m)\n",
        "\n",
        "# Make predictions for G3\n",
        "y_pred_g3_f = models['g3_female'].predict(X_test_mat_f)\n",
        "y_pred_g3_m = models['g3_male'].predict(X_test_mat_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test g1-g3 classification ( make this more robust)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Accuracy:\n",
            "G1 Female: 0.000\n",
            "G1 Male: 0.000\n",
            "G2 Female: 0.063\n",
            "G2 Male: 0.036\n",
            "\n",
            "Regression Performance:\n",
            "Female Model:\n",
            "MSE: 7.247\n",
            "R2: 0.726\n",
            "\n",
            "Male Model:\n",
            "MSE: 5.577\n",
            "R2: 0.691\n"
          ]
        }
      ],
      "source": [
        "# Evaluate G1 and G2 predictions\n",
        "print(\"Classification Accuracy:\")\n",
        "print(f\"G1 Female: {accuracy_score(y_test_mat_f['G1'], y_pred_g1_f):.3f}\")\n",
        "print(f\"G1 Male: {accuracy_score(y_test_mat_m['G1'], y_pred_g1_m):.3f}\")\n",
        "print(f\"G2 Female: {accuracy_score(y_test_mat_f['G2'], y_pred_g2_f):.3f}\")\n",
        "print(f\"G2 Male: {accuracy_score(y_test_mat_m['G2'], y_pred_g2_m):.3f}\")\n",
        "\n",
        "# Evaluate G3 predictions\n",
        "print(\"\\nRegression Performance:\")\n",
        "print(\"Female Model:\")\n",
        "print(f\"MSE: {mean_squared_error(y_test_mat_f['G3'], y_pred_g3_f):.3f}\")\n",
        "print(f\"R2: {r2_score(y_test_mat_f['G3'], y_pred_g3_f):.3f}\")\n",
        "\n",
        "print(\"\\nMale Model:\")\n",
        "print(f\"MSE: {mean_squared_error(y_test_mat_m['G3'], y_pred_g3_m):.3f}\")\n",
        "print(f\"R2: {r2_score(y_test_mat_m['G3'], y_pred_g3_m):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test G3 Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "G3 Regression Performance:\n",
            "Female Model:\n",
            "MSE: 7.247\n",
            "R2: 0.726\n",
            "\n",
            "Male Model:\n",
            "MSE: 5.577\n",
            "R2: 0.691\n"
          ]
        }
      ],
      "source": [
        "# Prepare G3 prediction data (including G1 and G2)\n",
        "X_test_mat_f_g3 = X_test_mat_f.copy()\n",
        "X_test_mat_m_g3 = X_test_mat_m.copy()\n",
        "\n",
        "# Make G3 predictions\n",
        "y_pred_g3_f = lr_g3_female.predict(X_test_mat_f_g3)\n",
        "y_pred_g3_m = lr_g3_male.predict(X_test_mat_m_g3)\n",
        "\n",
        "# Calculate regression metrics\n",
        "print(\"\\nG3 Regression Performance:\")\n",
        "print(\"Female Model:\")\n",
        "print(f\"MSE: {mean_squared_error(y_test_mat_f['G3'], y_pred_g3_f):.3f}\")\n",
        "print(f\"R2: {r2_score(y_test_mat_f['G3'], y_pred_g3_f):.3f}\")\n",
        "\n",
        "print(\"\\nMale Model:\")\n",
        "print(f\"MSE: {mean_squared_error(y_test_mat_m['G3'], y_pred_g3_m):.3f}\")\n",
        "print(f\"R2: {r2_score(y_test_mat_m['G3'], y_pred_g3_m):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'G1'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'G1'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate G1 and G2 predictions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m accuracy_g1_female \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[43mX_test_mat_f\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, X_test_mat_f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG1_pred\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m accuracy_g1_male \u001b[38;5;241m=\u001b[39m accuracy_score(X_test_mat_m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG1\u001b[39m\u001b[38;5;124m'\u001b[39m], X_test_mat_m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG1_pred\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m accuracy_g2_female \u001b[38;5;241m=\u001b[39m accuracy_score(X_test_mat_f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG2\u001b[39m\u001b[38;5;124m'\u001b[39m], X_test_mat_f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG2_pred\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'G1'"
          ]
        }
      ],
      "source": [
        "# Evaluate G1 and G2 predictions\n",
        "accuracy_g1_female = accuracy_score(X_test_mat_f['G1'], X_test_mat_f['G1_pred'])\n",
        "accuracy_g1_male = accuracy_score(X_test_mat_m['G1'], X_test_mat_m['G1_pred'])\n",
        "accuracy_g2_female = accuracy_score(X_test_mat_f['G2'], X_test_mat_f['G2_pred'])\n",
        "accuracy_g2_male = accuracy_score(X_test_mat_m['G2'], X_test_mat_m['G2_pred'])\n",
        "\n",
        "print(f\"G1 Female Accuracy: {accuracy_g1_female}\")\n",
        "print(f\"G1 Male Accuracy: {accuracy_g1_male}\")\n",
        "print(f\"G2 Female Accuracy: {accuracy_g2_female}\")\n",
        "print(f\"G2 Male Accuracy: {accuracy_g2_male}\")\n",
        "\n",
        "# Evaluate G3 predictions\n",
        "mse_g3_female = mean_squared_error(y_test_mat_f_g3, y_pred_mat_f_g3)\n",
        "r2_g3_female = r2_score(y_test_mat_f_g3, y_pred_mat_f_g3)\n",
        "mse_g3_male = mean_squared_error(y_test_mat_m_g3, y_pred_mat_m_g3)\n",
        "r2_g3_male = r2_score(y_test_mat_m_g3, y_pred_mat_m_g3)\n",
        "\n",
        "print(f\"G3 Female MSE: {mse_g3_female}\")\n",
        "print(f\"G3 Female R2: {r2_g3_female}\")\n",
        "print(f\"G3 Male MSE: {mse_g3_male}\")\n",
        "print(f\"G3 Male R2: {r2_g3_male}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
