{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Student secondary school performance based on primary school performance in math or Portuguese\n",
        "\n",
        "The scope and aim of this model is to use random forest models and linear regression averaging to find the relationship between student primary school performance and secondary school performance, using a range of features such as-\n",
        "\n",
        "## Attributes of our data, \n",
        "1. school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira).\n",
        "2. sex - student's sex (binary: 'F' - female or 'M' - male)\n",
        "3. age - student's age (numeric: from 15 to 22)\n",
        "4. address - student's home address type (binary: 'U' - urban or 'R' - rural)\n",
        "5. famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n",
        "6. Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\n",
        "7. Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
        "8. Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
        "9. Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
        "10. Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
        "11. reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n",
        "12. guardian - student's guardian (nominal: 'mother', 'father' or 'other')\n",
        "13. traveltime - home to school travel time (numeric: 1 - <15>1 hour)\n",
        "14. studytime - weekly study time (numeric: 1 - <2>10 hours)\n",
        "15. failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
        "16. schoolsup - extra educational support (binary: yes or no)\n",
        "17. famsup - family educational support (binary: yes or no)\n",
        "18. paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
        "19. activities - extra-curricular activities (binary: yes or no)\n",
        "20. nursery - attended nursery school (binary: yes or no)\n",
        "21. higher - wants to take higher education (binary: yes or no)\n",
        "22. internet - Internet access at home (binary: yes or no)\n",
        "23. romantic - with a romantic relationship (binary: yes or no)\n",
        "24. famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
        "25. freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
        "26. goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
        "27. Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
        "28. Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
        "29. health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
        "30. absences - number of school absences (numeric: from 0 to 93)\n",
        "\n",
        "these grades are related with the course subject, Math or Portuguese:\n",
        "31. G1 - first period grade (numeric: from 0 to 20)\n",
        "32. G2 - second period grade (numeric: from 0 to 20)\n",
        "33. G3 - final grade (numeric: from 0 to 20, output target)\n",
        "\n",
        "### (from these datasets)\n",
        "    > mat.arff // just the math results for G1-G3\n",
        "    > por.arff // just the portugese resutls for G1-G3\n",
        "    > dataset.csv // the \"combined\" data set of por and math results, without G1 or G2, with only G3 as target\n",
        "\n",
        "## Engineered features:\n",
        "1. Gvg - G1 and G2 average grade ( integer of (G1 + G2) /2)\n",
        "2. Avgalc - Average Dalc and Walc ( integer of (Dalc + Walc) /2)\n",
        "3. Bum - A weighted sum of failures, absences, Dalc, Walc, inverted studytime, and freetime to indicate a student's tendency to fail, skip school, drink alcohol, not study, and have free time.\n",
        "\n",
        "## Models and training methods\n",
        "We will use a random forest decision tree model for G1-G2 results, deciding the importance of the attributes at catergorising students, and a linear regression average for hte final G3 target predition. Each model is made of 3 parts, and there will be two models for math and portugese, and a seperate model for female and male. \n",
        "\n",
        "This will be acheived with model A, trained on finding the relationship between attributes and G1, fitting students into performance via fitting into group 1 through to 5,\n",
        "And thne model B trained on G2 results, doing the same decision training,\n",
        "and then model C that will train on these two models and attempt to find the average to predict a final G3 result. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import frameworks\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "from io import StringIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load ARFF files as CSV\n",
        "def load_arff_as_csv(filepath):\n",
        "    with open(filepath, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    data_start = False\n",
        "    data = []\n",
        "    for line in lines:\n",
        "        if data_start:\n",
        "            data.append(line.strip())\n",
        "        if line.strip().lower() == '@data':\n",
        "            data_start = True\n",
        "    return pd.read_csv(StringIO('\\n'.join(data)), header=None)\n",
        "\n",
        "# Load ARFF files\n",
        "mat_df = load_arff_as_csv('data/mat.arff')\n",
        "por_df = load_arff_as_csv('data/por.arff')\n",
        "\n",
        "# Set column names for mat.arff\n",
        "mat_columns = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n",
        "mat_df.columns = mat_columns\n",
        "\n",
        "# Set column names for por.arff\n",
        "por_columns = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n",
        "por_df.columns = por_columns\n",
        "\n",
        "# Load CSV file (which is actually in ARFF format)\n",
        "csv_columns = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G3']\n",
        "\n",
        "# Use the same ARFF loading function for dataset.csv\n",
        "csv_df = load_arff_as_csv('data/dataset.csv')\n",
        "csv_df.columns = csv_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Dealing with null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove Null values\n",
        "def remove_nulls(df):\n",
        "    df = df.dropna()\n",
        "    return df\n",
        "\n",
        "mat_df = remove_nulls(mat_df)\n",
        "por_df = remove_nulls(por_df)\n",
        "csv_df = remove_nulls(csv_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Remove Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove duplicates\n",
        "def remove_duplicates(df):\n",
        "    df = df.drop_duplicates()\n",
        "    return df\n",
        "\n",
        "mat_df = remove_duplicates(mat_df)\n",
        "por_df = remove_duplicates(por_df)\n",
        "csv_df = remove_duplicates(csv_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Replace data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace data\n",
        "def replace_data(df, column):\n",
        "    df[column] = df[column].apply(lambda x: x.lower())\n",
        "    return df\n",
        "\n",
        "mat_df = replace_data(mat_df, 'sex')\n",
        "por_df = replace_data(por_df, 'sex')\n",
        "csv_df = replace_data(csv_df, 'sex')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Remove outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outlier removal statistics:\n",
            "  • age: removed 1 outliers (bounds: 13.00 to 21.00)\n",
            "  • absences: removed 15 outliers (bounds: -12.00 to 20.00)\n",
            "  • G1: removed 0 outliers (bounds: 0.50 to 20.50)\n",
            "  • G2: removed 13 outliers (bounds: 3.00 to 19.00)\n",
            "  • G3: removed 25 outliers (bounds: 1.50 to 21.50)\n",
            "  • studytime: removed 24 outliers (bounds: -0.50 to 3.50)\n",
            "  • failures: removed 54 outliers (bounds: 0.00 to 0.00)\n",
            "  • Dalc: removed 12 outliers (bounds: -0.50 to 3.50)\n",
            "  • Walc: removed 0 outliers (bounds: -2.00 to 6.00)\n",
            "Total: 144 rows removed out of 395 (36.46%)\n",
            "Outlier removal statistics:\n",
            "  • age: removed 1 outliers (bounds: 13.00 to 21.00)\n",
            "  • absences: removed 21 outliers (bounds: -9.00 to 15.00)\n",
            "  • G1: removed 16 outliers (bounds: 5.50 to 17.50)\n",
            "  • G2: removed 15 outliers (bounds: 5.50 to 17.50)\n",
            "  • G3: removed 7 outliers (bounds: 4.00 to 20.00)\n",
            "  • studytime: removed 31 outliers (bounds: -0.50 to 3.50)\n",
            "  • failures: removed 78 outliers (bounds: 0.00 to 0.00)\n",
            "  • Dalc: removed 19 outliers (bounds: -0.50 to 3.50)\n",
            "  • Walc: removed 0 outliers (bounds: -2.00 to 6.00)\n",
            "Total: 188 rows removed out of 649 (28.97%)\n",
            "Outlier removal statistics:\n",
            "  • age: removed 1 outliers (bounds: 13.00 to 21.00)\n",
            "  • absences: removed 21 outliers (bounds: -9.00 to 15.00)\n",
            "  • G3: removed 16 outliers (bounds: 4.00 to 20.00)\n",
            "  • studytime: removed 35 outliers (bounds: -0.50 to 3.50)\n",
            "  • failures: removed 81 outliers (bounds: 0.00 to 0.00)\n",
            "  • Dalc: removed 19 outliers (bounds: -0.50 to 3.50)\n",
            "  • Walc: removed 0 outliers (bounds: -2.00 to 6.00)\n",
            "Total: 173 rows removed out of 649 (26.66%)\n"
          ]
        }
      ],
      "source": [
        "# Remove outliers using IQR method across multiple columns\n",
        "def remove_outliers(df, columns_to_check=['age', 'absences', 'G1', 'G2', 'G3']):\n",
        "    df_clean = df.copy()\n",
        "    original_rows = len(df_clean)\n",
        "    \n",
        "    print(\"Outlier removal statistics:\")\n",
        "    for col in columns_to_check:\n",
        "        if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
        "            # Calculate IQR\n",
        "            Q1 = df_clean[col].quantile(0.25)\n",
        "            Q3 = df_clean[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            \n",
        "            # Define bounds\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            \n",
        "            # Count outliers before removal\n",
        "            outliers_count = df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)].shape[0]\n",
        "            \n",
        "            # Remove outliers\n",
        "            df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
        "            \n",
        "            # Print statistics\n",
        "            print(f\"  • {col}: removed {outliers_count} outliers (bounds: {lower_bound:.2f} to {upper_bound:.2f})\")\n",
        "    \n",
        "    # Print summary\n",
        "    rows_removed = original_rows - len(df_clean)\n",
        "    print(f\"Total: {rows_removed} rows removed out of {original_rows} ({rows_removed/original_rows*100:.2f}%)\")\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "# Apply enhanced outlier detection to all datasets\n",
        "numerical_columns = ['age', 'absences', 'G1', 'G2', 'G3', 'studytime', 'failures', 'Dalc', 'Walc']\n",
        "mat_df = remove_outliers(mat_df, numerical_columns)\n",
        "por_df = remove_outliers(por_df, numerical_columns)\n",
        "csv_df = remove_outliers(csv_df, numerical_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Scaling features to a common range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Applying feature scaling:\n",
            "Scaled features: age, Medu, Fedu, traveltime, studytime, failures, famrel, freetime, goout, Dalc, Walc, health, absences\n",
            "Scaled features: age, Medu, Fedu, traveltime, studytime, failures, famrel, freetime, goout, Dalc, Walc, health, absences\n",
            "Scaled features: age, Medu, Fedu, traveltime, studytime, failures, famrel, freetime, goout, Dalc, Walc, health, absences\n"
          ]
        }
      ],
      "source": [
        "# Scale numerical features to a common range [0,1]\n",
        "def scale_features(df, columns_to_scale):\n",
        "    df_scaled = df.copy()\n",
        "    \n",
        "    # Filter only existing numerical columns\n",
        "    valid_columns = [col for col in columns_to_scale \n",
        "                    if col in df.columns and pd.api.types.is_numeric_dtype(df[col])]\n",
        "    \n",
        "    if valid_columns:\n",
        "        # Apply scaling\n",
        "        scaler = MinMaxScaler()\n",
        "        df_scaled[valid_columns] = scaler.fit_transform(df[valid_columns])\n",
        "        print(f\"Scaled features: {', '.join(valid_columns)}\")\n",
        "    \n",
        "    return df_scaled\n",
        "\n",
        "# Define which numerical columns should be scaled\n",
        "numerical_features = [\n",
        "    'age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures',\n",
        "    'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences'\n",
        "]\n",
        "\n",
        "# Apply scaling to all datasets\n",
        "print(\"\\nApplying feature scaling:\")\n",
        "mat_df = scale_features(mat_df, numerical_features)\n",
        "por_df = scale_features(por_df, numerical_features)\n",
        "csv_df = scale_features(csv_df, numerical_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save the wrangled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create directory if it doesn't exist\n",
        "os.makedirs('processed_data', exist_ok=True)\n",
        "\n",
        "# Save the processed data files\n",
        "mat_df.to_csv('processed_data/Pmat_full.csv', index=False)\n",
        "por_df.to_csv('processed_data/Ppor_full.csv', index=False)\n",
        "csv_df.to_csv('processed_data/Pdataset.csv', index=False)\n",
        "# Raw processed data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split by gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outlier removal statistics:\n",
            "Total: 0 rows removed out of 251 (0.00%)\n",
            "Unique values in sex column (Math): [\"'f'\" \"'m'\"]\n",
            "Outlier removal statistics:\n",
            "Total: 0 rows removed out of 461 (0.00%)\n",
            "Unique values in sex column (Portuguese): [\"'f'\" \"'m'\"]\n",
            "\n",
            "Gender Distribution after Outlier Removal:\n",
            "\n",
            "Mathematics Dataset:\n",
            "Female: 132 (52.6%)\n",
            "Male: 119 (47.4%)\n",
            "\n",
            "Portuguese Dataset:\n",
            "Female: 282 (61.2%)\n",
            "Male: 179 (38.8%)\n",
            "\n",
            "Files saved in processed_data folder\n"
          ]
        }
      ],
      "source": [
        "# Create processed_data directory if it doesn't exist\n",
        "os.makedirs('processed_data', exist_ok=True)\n",
        "\n",
        "# Process Mathematics data\n",
        "mat_df = remove_outliers(mat_df, 'age')\n",
        "# Check unique values in sex column\n",
        "print(\"Unique values in sex column (Math):\", mat_df['sex'].unique())\n",
        "PmatFE = mat_df[mat_df['sex'].str.contains('F', case=False)].copy()\n",
        "PmatM = mat_df[mat_df['sex'].str.contains('M', case=False)].copy()\n",
        "\n",
        "# Process Portuguese data\n",
        "por_df = remove_outliers(por_df, 'age')\n",
        "print(\"Unique values in sex column (Portuguese):\", por_df['sex'].unique())\n",
        "PporFE = por_df[por_df['sex'].str.contains('F', case=False)].copy()\n",
        "PporM = por_df[por_df['sex'].str.contains('M', case=False)].copy()\n",
        "\n",
        "# Save gender-split datasets\n",
        "PmatFE.to_csv('processed_data/PmatFE.csv', index=False)\n",
        "PmatM.to_csv('processed_data/PmatM.csv', index=False)\n",
        "PporFE.to_csv('processed_data/PporFE.csv', index=False)\n",
        "PporM.to_csv('processed_data/PporM.csv', index=False)\n",
        "\n",
        "# Print verification statistics\n",
        "print(\"\\nGender Distribution after Outlier Removal:\")\n",
        "print(\"\\nMathematics Dataset:\")\n",
        "print(f\"Female: {len(PmatFE)} ({len(PmatFE)/len(mat_df)*100:.1f}%)\")\n",
        "print(f\"Male: {len(PmatM)} ({len(PmatM)/len(mat_df)*100:.1f}%)\")\n",
        "print(\"\\nPortuguese Dataset:\")\n",
        "print(f\"Female: {len(PporFE)} ({len(PporFE)/len(por_df)*100:.1f}%)\")\n",
        "print(f\"Male: {len(PporM)} ({len(PporM)/len(por_df)*100:.1f}%)\")\n",
        "print(\"\\nFiles saved in processed_data folder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split data for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing and saving train-test splits...\n",
            "\n",
            "PmatFE:\n",
            "Training: 105 samples\n",
            "Testing: 27 samples\n",
            "\n",
            "PmatM:\n",
            "Training: 95 samples\n",
            "Testing: 24 samples\n",
            "\n",
            "PporFE:\n",
            "Training: 225 samples\n",
            "Testing: 57 samples\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 5, got 4)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[50], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m X_train_mat_m, X_test_mat_m, y_train_mat_m, y_test_mat_m \u001b[38;5;241m=\u001b[39m split_save_and_print(PmatM, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPmatM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Portuguese splits\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m X_train_por_f,X_train_por_f, X_test_por_f, y_train_por_f, y_test_por_f \u001b[38;5;241m=\u001b[39m split_save_and_print(PporFE, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPporFE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m X_train_por_m, X_test_por_m, y_train_por_m, y_test_por_m \u001b[38;5;241m=\u001b[39m split_save_and_print(PporM, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPporM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll splits have been saved to the processed_data folder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
          ]
        }
      ],
      "source": [
        "# Function to split and save datasets\n",
        "def split_save_and_print(data, name, test_size=0.2, random_state=42):\n",
        "    X = data.drop(['sex', 'G1', 'G2', 'G3'], axis=1)\n",
        "    y = data[['G1', 'G2', 'G3']]\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    \n",
        "    # Save splits with new naming convention\n",
        "    base_path = 'processed_data'\n",
        "    X_train.to_csv(f'{base_path}/X_{name}_train.csv', index=False)\n",
        "    X_test.to_csv(f'{base_path}/X_{name}_test.csv', index=False)\n",
        "    y_train.to_csv(f'{base_path}/Y_{name}_train.csv', index=False)\n",
        "    y_test.to_csv(f'{base_path}/Y_{name}_test.csv', index=False)\n",
        "    \n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"Training: {X_train.shape[0]} samples\")\n",
        "    print(f\"Testing: {X_test.shape[0]} samples\")\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "print(\"Performing and saving train-test splits...\")\n",
        "\n",
        "# Mathematics splits\n",
        "X_train_mat_f, X_test_mat_f, y_train_mat_f, y_test_mat_f = split_save_and_print(PmatFE, \"PmatFE\")\n",
        "X_train_mat_m, X_test_mat_m, y_train_mat_m, y_test_mat_m = split_save_and_print(PmatM, \"PmatM\")\n",
        "\n",
        "# Portuguese splits\n",
        "X_train_por_f,X_train_por_f, X_test_por_f, y_train_por_f, y_test_por_f = split_save_and_print(PporFE, \"PporFE\")\n",
        "X_train_por_m, X_test_por_m, y_train_por_m, y_test_por_m = split_save_and_print(PporM, \"PporM\")\n",
        "\n",
        "print(\"\\nAll splits have been saved to the processed_data folder\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
