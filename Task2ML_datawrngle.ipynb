{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student performance prediction based on previous performance\n",
    "\n",
    "Our data set contains a lot of features and attributes, our aim is to use random forest model prediction on G1, with separate versions for female and male, a prediction model for G2 for male and female, and then a final linear regression model to predict G3 based on G1 and G2 predictions/input data.\n",
    "\n",
    "## Attributes and Datasets\n",
    "### List of basic attributes\n",
    "\n",
    "| # | Attribute | Description |\n",
    "|---|-----------|-------------|\n",
    "| 1 | school | Student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) |\n",
    "| 2 | sex | Student's sex (binary: 'F' - female or 'M' - male) |\n",
    "| 3 | age | Student's age (numeric: from 15 to 22) |\n",
    "| 4 | address | Student's home address type (binary: 'U' - urban or 'R' - rural) |\n",
    "| 5 | famsize | Family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) |\n",
    "| 6 | Pstatus | Parent's cohabitation status (binary: 'T' - living together or 'A' - apart) |\n",
    "| 7 | Medu | Mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education) |\n",
    "| 8 | Fedu | Father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education) |\n",
    "| 9 | Mjob | Mother's job (nominal: 'teacher', 'health' care related, civil 'services', 'at_home' or 'other') |\n",
    "| 10 | Fjob | Father's job (nominal: 'teacher', 'health' care related, civil 'services', 'at_home' or 'other') |\n",
    "| 11 | reason | Reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') |\n",
    "| 12 | guardian | Student's guardian (nominal: 'mother', 'father' or 'other') |\n",
    "| 13 | traveltime | Home to school travel time (numeric: 1 - <15 min., 2 - 15-30 min., 3 - 30-60 min., 4 - >60 min.) |\n",
    "| 14 | studytime | Weekly study time (numeric: 1 - <2 hours, 2 - 2-5 hours, 3 - 5-10 hours, 4 - >10 hours) |\n",
    "| 15 | failures | Number of past class failures (numeric: n if 1<=n<3, else 4) |\n",
    "| 16 | schoolsup | Extra educational support (binary: yes or no) |\n",
    "| 17 | famsup | Family educational support (binary: yes or no) |\n",
    "| 18 | paid | Extra paid classes within the course subject (binary: yes or no) |\n",
    "| 19 | activities | Extra-curricular activities (binary: yes or no) |\n",
    "| 20 | nursery | Attended nursery school (binary: yes or no) |\n",
    "| 21 | higher | Wants to take higher education (binary: yes or no) |\n",
    "| 22 | internet | Internet access at home (binary: yes or no) |\n",
    "| 23 | romantic | With a romantic relationship (binary: yes or no) |\n",
    "| 24 | famrel | Quality of family relationships (numeric: from 1 - very bad to 5 - excellent) |\n",
    "| 25 | freetime | Free time after school (numeric: from 1 - very low to 5 - very high) |\n",
    "| 26 | goout | Going out with friends (numeric: from 1 - very low to 5 - very high) |\n",
    "| 27 | Dalc | Workday alcohol consumption (numeric: from 1 - very low to 5 - very high) |\n",
    "| 28 | Walc | Weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) |\n",
    "| 29 | health | Current health status (numeric: from 1 - very bad to 5 - very good) |\n",
    "| 30 | absences | Number of school absences (numeric: from 0 to 93) |\n",
    "\n",
    "**Grade-related attributes:**\n",
    "| # | Attribute | Description |\n",
    "|---|-----------|-------------|\n",
    "| 31 | G1 | First period grade (numeric: from 0 to 20) |\n",
    "| 32 | G2 | Second period grade (numeric: from 0 to 20) |\n",
    "| 33 | G3 | Final grade (numeric: from 0 to 20, output target) |\n",
    "\n",
    "### Datasets\n",
    "- `mat.arff` - contains attributes, G1-G3 math results\n",
    "- `por.arff` - contains attributes, G1-G3 portuguese results\n",
    "- `dataset.csv` - contains all attributes, G3 math and portuguese results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling for Student Performance Datasets\n",
    "\n",
    "This notebook demonstrates data wrangling for the student performance datasets (`mat.arff`, `por.arff`, and `dataset.csv`). The processed data will be saved in the `processed_data` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependancies and frameworks\n",
    "Load the two required dependencies:\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/) is library that allows us to handle data for wrangling and visualisation.\n",
    "- [sklearn](https://scikit-learn.org/stable/) A framework for training Machine Learning, we will use this for wrangling, but also applies to training and testing.\n",
    "- [os, IO](https://docs.python.org/3/library) Default packages installed with python, allows us to create, save and edit files with basic string functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ARFF files as CSV\n",
    "def load_arff_as_csv(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    data_start = False\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        if data_start:\n",
    "            data.append(line.strip())\n",
    "        if line.strip().lower() == '@data':\n",
    "            data_start = True\n",
    "    return pd.read_csv(StringIO('\\n'.join(data)), header=None)\n",
    "\n",
    "# Load ARFF files\n",
    "mat_df = load_arff_as_csv('data/mat.arff')\n",
    "por_df = load_arff_as_csv('data/por.arff')\n",
    "\n",
    "# Set column names for mat.arff\n",
    "mat_columns = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n",
    "mat_df.columns = mat_columns\n",
    "\n",
    "# Set column names for por.arff\n",
    "por_columns = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n",
    "por_df.columns = por_columns\n",
    "\n",
    "# Load CSV file (which is actually in ARFF format)\n",
    "csv_columns = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G3']\n",
    "\n",
    "# Use the same ARFF loading function for dataset.csv\n",
    "csv_df = load_arff_as_csv('data/dataset.csv')\n",
    "csv_df.columns = csv_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Null values\n",
    "def remove_nulls(df):\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "mat_df = remove_nulls(mat_df)\n",
    "por_df = remove_nulls(por_df)\n",
    "csv_df = remove_nulls(csv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "def remove_duplicates(df):\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "mat_df = remove_duplicates(mat_df)\n",
    "por_df = remove_duplicates(por_df)\n",
    "csv_df = remove_duplicates(csv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace data\n",
    "def replace_data(df, column):\n",
    "    df[column] = df[column].apply(lambda x: x.lower())\n",
    "    return df\n",
    "\n",
    "mat_df = replace_data(mat_df, 'sex')\n",
    "por_df = replace_data(por_df, 'sex')\n",
    "csv_df = replace_data(csv_df, 'sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df = df[(df[column] >= Q1 - 1.5 * IQR) & (df[column] <= Q3 + 1.5 * IQR)]\n",
    "    return df\n",
    "\n",
    "mat_df = remove_outliers(mat_df, 'age')\n",
    "por_df = remove_outliers(por_df, 'age')\n",
    "csv_df = remove_outliers(csv_df, 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling features to a common range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "# this would normally be something like this\n",
    "# scaler = MinMaxScaler()\n",
    "# mat_df[['age', 'absences', 'G3']] = scaler.fit_transform(mat_df[['age', 'absences', 'G3']])\n",
    "# por_df[['age', 'absences', 'G3']] = scaler.fit_transform(por_df[['age', 'absences', 'G3']])\n",
    "# csv_df[['age', 'absences', 'G3']] = scaler.fit_transform(csv_df[['age', 'absences', 'G3']])\n",
    "\n",
    "# but for this use case, this data should not be scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wrangled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory if it doesn't exist\n",
    "os.makedirs('processed_data', exist_ok=True)\n",
    "\n",
    "# Save the processed data files\n",
    "mat_df.to_csv('processed_data/Pmat.csv', index=False)\n",
    "por_df.to_csv('processed_data/Ppor.csv', index=False)\n",
    "csv_df.to_csv('processed_data/Pdataset.csv', index=False)\n",
    "# Raw processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding numerical and categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_variables(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Binary and nominal encodings\n",
    "    encodings = {\n",
    "        'school': {'gp': 0, 'ms': 1},\n",
    "        'sex': {'f': 0, 'm': 1},\n",
    "        'address': {'u': 0, 'r': 1},\n",
    "        'famsize': {'le3': 0, 'gt3': 1},\n",
    "        'Pstatus': {'t': 0, 'a': 1},\n",
    "        'Mjob': {'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4},\n",
    "        'Fjob': {'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4},\n",
    "        'reason': {'home': 0, 'reputation': 1, 'course': 2, 'other': 3},\n",
    "        'guardian': {'mother': 0, 'father': 1, 'other': 2},\n",
    "        'schoolsup': {'no': 0, 'yes': 1},\n",
    "        'famsup': {'no': 0, 'yes': 1},\n",
    "        'paid': {'no': 0, 'yes': 1},\n",
    "        'activities': {'no': 0, 'yes': 1},\n",
    "        'nursery': {'no': 0, 'yes': 1},\n",
    "        'higher': {'no': 0, 'yes': 1},\n",
    "        'internet': {'no': 0, 'yes': 1},\n",
    "        'romantic': {'no': 0, 'yes': 1}\n",
    "    }\n",
    "    \n",
    "    # Clean and encode each column\n",
    "    for col, mapping in encodings.items():\n",
    "        if col in df.columns:\n",
    "            # convert to lowercase and strip any whitespace/quotes\n",
    "            df[col] = df[col].str.lower().str.strip().str.strip(\"'\")\n",
    "            # encode\n",
    "            df[col] = df[col].map(mapping)\n",
    "            \n",
    "            # verify encoding worked\n",
    "            if df[col].isna().any():\n",
    "                print(f\"Warning: NaN values found in {col} after encoding\")\n",
    "                print(f\"Unique values before encoding: {df[col].unique()}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Statistics after Processing:\n",
      "\n",
      "Mathematics Dataset:\n",
      "Total: 394 samples\n",
      "Female: 208 (52.8%)\n",
      "Male: 186 (47.2%)\n",
      "\n",
      "Portuguese Dataset:\n",
      "Total: 648 samples\n",
      "Female: 383 (59.1%)\n",
      "Male: 265 (40.9%)\n",
      "\n",
      "Sample of encoded values:\n",
      "   sex  school  address  Mjob\n",
      "0    0       0        0     3\n",
      "1    0       0        0     3\n",
      "2    0       0        0     3\n",
      "3    0       0        0     1\n",
      "4    0       0        0     4\n"
     ]
    }
   ],
   "source": [
    "def split_by_gender(df):\n",
    "    \"\"\"Split dataframe by gender after encoding\"\"\"\n",
    "    female_df = df[df['sex'] == 0].copy()\n",
    "    male_df = df[df['sex'] == 1].copy()\n",
    "    return female_df, male_df\n",
    "\n",
    "# Process Mathematics data\n",
    "mat_df = remove_outliers(mat_df, 'age')\n",
    "Pmat_full = mat_df.copy()\n",
    "# ecode\n",
    "Pmat_full = encode_categorical_variables(Pmat_full)\n",
    "# Split by gender\n",
    "PmatFE, PmatM = split_by_gender(Pmat_full)\n",
    "\n",
    "# Process Portuguese data\n",
    "por_df = remove_outliers(por_df, 'age')\n",
    "Ppor_full = por_df.copy()\n",
    "# ecode\n",
    "Ppor_full = encode_categorical_variables(Ppor_full)\n",
    "# Split by gender\n",
    "PporFE, PporM = split_by_gender(Ppor_full)\n",
    "\n",
    "# Save datasets\n",
    "Pmat_full.to_csv('processed_data/Pmat_full.csv', index=False)\n",
    "Ppor_full.to_csv('processed_data/Ppor_full.csv', index=False)\n",
    "PmatFE.to_csv('processed_data/PmatFE.csv', index=False)\n",
    "PmatM.to_csv('processed_data/PmatM.csv', index=False)\n",
    "PporFE.to_csv('processed_data/PporFE.csv', index=False)\n",
    "PporM.to_csv('processed_data/PporM.csv', index=False)\n",
    "\n",
    "# Print verification statistics\n",
    "print(\"\\nDataset Statistics after Processing:\")\n",
    "print(\"\\nMathematics Dataset:\")\n",
    "print(f\"Total: {len(Pmat_full)} samples\")\n",
    "print(f\"Female: {len(PmatFE)} ({len(PmatFE)/len(mat_df)*100:.1f}%)\")\n",
    "print(f\"Male: {len(PmatM)} ({len(PmatM)/len(mat_df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nPortuguese Dataset:\")\n",
    "print(f\"Total: {len(Ppor_full)} samples\")\n",
    "print(f\"Female: {len(PporFE)} ({len(PporFE)/len(por_df)*100:.1f}%)\")\n",
    "print(f\"Male: {len(PporM)} ({len(PporM)/len(por_df)*100:.1f}%)\")\n",
    "\n",
    "# Print sample of encoded values for verification\n",
    "print(\"\\nSample of encoded values:\")\n",
    "print(Pmat_full[['sex', 'school', 'address', 'Mjob']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving this, but we are not using this, as we split the data again in feature\n",
    "\n",
    "`\n",
    "# Function to split and save datasets\n",
    "def split_save_and_print(data, name, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['sex', 'G1', 'G2', 'G3'], axis=1),\n",
    "        data[['G1', 'G2', 'G3']],\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Save splits\n",
    "    base_path = f'processed_data/{name.lower().replace(\" \", \"_\")}'\n",
    "    X_train.to_csv(f'{base_path}_X_train.csv', index=False)\n",
    "    X_test.to_csv(f'{base_path}_X_test.csv', index=False)\n",
    "    y_train.to_csv(f'{base_path}_y_train.csv', index=False)\n",
    "    y_test.to_csv(f'{base_path}_y_test.csv', index=False)\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Training: {X_train.shape[0]} samples\")\n",
    "    print(f\"Testing: {X_test.shape[0]} samples\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "print(\"Performing and saving train-test splits...\")\n",
    "\n",
    "# Mathematics splits\n",
    "X_train_mat_f, X_test_mat_f, y_train_mat_f, y_test_mat_f = split_save_and_print(PmatFemale, \"Mathematics Female\")\n",
    "X_train_mat_m, X_test_mat_m, y_train_mat_m, y_test_mat_m = split_save_and_print(PmatMale, \"Mathematics Male\")\n",
    "\n",
    "# Portuguese splits\n",
    "X_train_por_f, X_test_por_f, y_train_por_f, y_test_por_f = split_save_and_print(PporFemale, \"Portuguese Female\")\n",
    "X_train_por_m, X_test_por_m, y_train_por_m, y_test_por_m = split_save_and_print(PporMale, \"Portuguese Male\")\n",
    "\n",
    "print(\"All splits have been saved to the processed_data folder\")\n",
    "\n",
    "`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
