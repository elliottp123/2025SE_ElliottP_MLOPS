{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student performance prediction based on previous performance\n",
    "\n",
    "Our data set contains a lot of features and attributes, our aim is to use random forest model prediction on G1, with separate versions for female and male, a prediction model for G2 for male and female, and then a final linear regression model to predict G3 based on G1 and G2 predictions/input data.\n",
    "\n",
    "## Attributes and Datasets\n",
    "### List of basic attributes\n",
    "\n",
    "| # | Attribute | Description |\n",
    "|---|-----------|-------------|\n",
    "| 1 | school | Student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) |\n",
    "| 2 | sex | Student's sex (binary: 'F' - female or 'M' - male) |\n",
    "| 3 | age | Student's age (numeric: from 15 to 22) |\n",
    "| 4 | address | Student's home address type (binary: 'U' - urban or 'R' - rural) |\n",
    "| 5 | famsize | Family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) |\n",
    "| 6 | Pstatus | Parent's cohabitation status (binary: 'T' - living together or 'A' - apart) |\n",
    "| 7 | Medu | Mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education) |\n",
    "| 8 | Fedu | Father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education) |\n",
    "| 9 | Mjob | Mother's job (nominal: 'teacher', 'health' care related, civil 'services', 'at_home' or 'other') |\n",
    "| 10 | Fjob | Father's job (nominal: 'teacher', 'health' care related, civil 'services', 'at_home' or 'other') |\n",
    "| 11 | reason | Reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') |\n",
    "| 12 | guardian | Student's guardian (nominal: 'mother', 'father' or 'other') |\n",
    "| 13 | traveltime | Home to school travel time (numeric: 1 - <15 min., 2 - 15-30 min., 3 - 30-60 min., 4 - >60 min.) |\n",
    "| 14 | studytime | Weekly study time (numeric: 1 - <2 hours, 2 - 2-5 hours, 3 - 5-10 hours, 4 - >10 hours) |\n",
    "| 15 | failures | Number of past class failures (numeric: n if 1<=n<3, else 4) |\n",
    "| 16 | schoolsup | Extra educational support (binary: yes or no) |\n",
    "| 17 | famsup | Family educational support (binary: yes or no) |\n",
    "| 18 | paid | Extra paid classes within the course subject (binary: yes or no) |\n",
    "| 19 | activities | Extra-curricular activities (binary: yes or no) |\n",
    "| 20 | nursery | Attended nursery school (binary: yes or no) |\n",
    "| 21 | higher | Wants to take higher education (binary: yes or no) |\n",
    "| 22 | internet | Internet access at home (binary: yes or no) |\n",
    "| 23 | romantic | With a romantic relationship (binary: yes or no) |\n",
    "| 24 | famrel | Quality of family relationships (numeric: from 1 - very bad to 5 - excellent) |\n",
    "| 25 | freetime | Free time after school (numeric: from 1 - very low to 5 - very high) |\n",
    "| 26 | goout | Going out with friends (numeric: from 1 - very low to 5 - very high) |\n",
    "| 27 | Dalc | Workday alcohol consumption (numeric: from 1 - very low to 5 - very high) |\n",
    "| 28 | Walc | Weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) |\n",
    "| 29 | health | Current health status (numeric: from 1 - very bad to 5 - very good) |\n",
    "| 30 | absences | Number of school absences (numeric: from 0 to 93) |\n",
    "\n",
    "**Grade-related attributes:**\n",
    "| # | Attribute | Description |\n",
    "|---|-----------|-------------|\n",
    "| 31 | G1 | First period grade (numeric: from 0 to 20) |\n",
    "| 32 | G2 | Second period grade (numeric: from 0 to 20) |\n",
    "| 33 | G3 | Final grade (numeric: from 0 to 20, output target) |\n",
    "\n",
    "### Datasets\n",
    "- `mat.arff` - contains attributes, G1-G3 math results\n",
    "- `por.arff` - contains attributes, G1-G3 portuguese results\n",
    "- `dataset.csv` - contains all attributes, G3 math and portuguese results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling for Student Performance Datasets\n",
    "\n",
    "This notebook demonstrates data wrangling for the student performance datasets (`mat.arff`, `por.arff`, and `dataset.csv`). The processed data will be saved in the `processed_data` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependancies and frameworks\n",
    "Load the two required dependencies:\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/) is library that allows us to handle data for wrangling and visualisation.\n",
    "- [sklearn](https://scikit-learn.org/stable/) A framework for training Machine Learning, we will use this for wrangling, but also applies to training and testing.\n",
    "- [os, IO](https://docs.python.org/3/library) Default packages installed with python, allows us to create, save and edit files with basic string functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ARFF files as CSV\n",
    "def load_arff_as_csv(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    data_start = False\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        if data_start:\n",
    "            data.append(line.strip())\n",
    "        if line.strip().lower() == '@data':\n",
    "            data_start = True\n",
    "    return pd.read_csv(StringIO('\\n'.join(data)), header=None)\n",
    "\n",
    "# Load ARFF files\n",
    "mat_df = load_arff_as_csv('data/mat.arff')\n",
    "por_df = load_arff_as_csv('data/por.arff')\n",
    "\n",
    "# Set column names for mat.arff\n",
    "mat_columns = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n",
    "mat_df.columns = mat_columns\n",
    "\n",
    "# Set column names for por.arff\n",
    "por_columns = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n",
    "por_df.columns = por_columns\n",
    "\n",
    "# Load CSV file (which is actually in ARFF format)\n",
    "csv_columns = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G3']\n",
    "\n",
    "# Use the same ARFF loading function for dataset.csv\n",
    "csv_df = load_arff_as_csv('data/dataset.csv')\n",
    "csv_df.columns = csv_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Null values\n",
    "def remove_nulls(df):\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "mat_df = remove_nulls(mat_df)\n",
    "por_df = remove_nulls(por_df)\n",
    "csv_df = remove_nulls(csv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "def remove_duplicates(df):\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "mat_df = remove_duplicates(mat_df)\n",
    "por_df = remove_duplicates(por_df)\n",
    "csv_df = remove_duplicates(csv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace data\n",
    "def replace_data(df, column):\n",
    "    df[column] = df[column].apply(lambda x: x.lower())\n",
    "    return df\n",
    "\n",
    "mat_df = replace_data(mat_df, 'sex')\n",
    "por_df = replace_data(por_df, 'sex')\n",
    "csv_df = replace_data(csv_df, 'sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df = df[(df[column] >= Q1 - 1.5 * IQR) & (df[column] <= Q3 + 1.5 * IQR)]\n",
    "    return df\n",
    "\n",
    "mat_df = remove_outliers(mat_df, 'age')\n",
    "por_df = remove_outliers(por_df, 'age')\n",
    "csv_df = remove_outliers(csv_df, 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling features to a common range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "# this would normally be something like this\n",
    "# scaler = MinMaxScaler()\n",
    "# mat_df[['age', 'absences', 'G3']] = scaler.fit_transform(mat_df[['age', 'absences', 'G3']])\n",
    "# por_df[['age', 'absences', 'G3']] = scaler.fit_transform(por_df[['age', 'absences', 'G3']])\n",
    "# csv_df[['age', 'absences', 'G3']] = scaler.fit_transform(csv_df[['age', 'absences', 'G3']])\n",
    "\n",
    "# but for this use case, this data should not be scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wrangled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory if it doesn't exist\n",
    "os.makedirs('processed_data', exist_ok=True)\n",
    "\n",
    "# Save the processed data files\n",
    "mat_df.to_csv('processed_data/Pmat.csv', index=False)\n",
    "por_df.to_csv('processed_data/Ppor.csv', index=False)\n",
    "csv_df.to_csv('processed_data/Pdataset.csv', index=False)\n",
    "# Raw processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Distribution after Outlier Removal:\n",
      "\n",
      "Mathematics Dataset:\n",
      "Female: 0 (0.0%)\n",
      "Male: 0 (0.0%)\n",
      "\n",
      "Portuguese Dataset:\n",
      "Female: 0 (0.0%)\n",
      "Male: 0 (0.0%)\n",
      "\n",
      "Files saved in processed_data folder\n"
     ]
    }
   ],
   "source": [
    "# Create processed_data directory if it doesn't exist\n",
    "os.makedirs('processed_data', exist_ok=True)\n",
    "\n",
    "# Process Mathematics data\n",
    "mat_df = remove_outliers(mat_df, 'age')\n",
    "PmatFE = mat_df[mat_df['sex'] == 'F'].copy()\n",
    "PmatM = mat_df[mat_df['sex'] == 'M'].copy()\n",
    "\n",
    "# Process Portuguese data\n",
    "por_df = remove_outliers(por_df, 'age')\n",
    "PporFE = por_df[por_df['sex'] == 'F'].copy()\n",
    "PporM = por_df[por_df['sex'] == 'M'].copy()\n",
    "\n",
    "# Create training data splits for each gender/subject combination\n",
    "splits = {\n",
    "    'X_PmatFE': PmatFE,\n",
    "    'X_PmatM': PmatM,\n",
    "    'X_PporFE': PporFE,\n",
    "    'X_PporM': PporM\n",
    "}\n",
    "\n",
    "# Save splits with features and targets separated\n",
    "for name, data in splits.items():\n",
    "    # Features for G1 (excluding all grades)\n",
    "    X = data.drop(['G1', 'G2', 'G3'], axis=1)\n",
    "    y_g1 = data['G1']\n",
    "    \n",
    "    # Save splits\n",
    "    X.to_csv(f'processed_data/{name}.csv', index=False)\n",
    "    y_g1.to_csv(f'processed_data/{name}_g1.csv', index=False)\n",
    "    # Save full data for later G2/G3 predictions\n",
    "    data.to_csv(f'processed_data/{name}_full.csv', index=False)\n",
    "\n",
    "# Print verification statistics\n",
    "print(\"Gender Distribution after Outlier Removal:\")\n",
    "print(\"\\nMathematics Dataset:\")\n",
    "print(f\"Female: {len(PmatFE)} ({len(PmatFE)/len(mat_df)*100:.1f}%)\")\n",
    "print(f\"Male: {len(PmatM)} ({len(PmatM)/len(mat_df)*100:.1f}%)\")\n",
    "print(\"\\nPortuguese Dataset:\")\n",
    "print(f\"Female: {len(PporFE)} ({len(PporFE)/len(por_df)*100:.1f}%)\")\n",
    "print(f\"Male: {len(PporM)} ({len(PporM)/len(por_df)*100:.1f}%)\")\n",
    "print(\"\\nFiles saved in processed_data folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing and saving train-test splits...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming and saving train-test splits...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Mathematics splits\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m X_train_mat_f, X_test_mat_f, y_train_mat_f, y_test_mat_f \u001b[38;5;241m=\u001b[39m \u001b[43msplit_save_and_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPmatFemale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMathematics Female\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m X_train_mat_m, X_test_mat_m, y_train_mat_m, y_test_mat_m \u001b[38;5;241m=\u001b[39m split_save_and_print(PmatMale, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMathematics Male\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Portuguese splits\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m, in \u001b[0;36msplit_save_and_print\u001b[0;34m(data, name, test_size, random_state)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_save_and_print\u001b[39m(data, name, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Save splits\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2481\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2478\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2485\u001b[0m     )\n\u001b[1;32m   2487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to split and save datasets\n",
    "def split_save_and_print(data, name, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['sex', 'G1', 'G2', 'G3'], axis=1),\n",
    "        data[['G1', 'G2', 'G3']],\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Save splits\n",
    "    base_path = f'processed_data/{name.lower().replace(\" \", \"_\")}'\n",
    "    X_train.to_csv(f'{base_path}_X_train.csv', index=False)\n",
    "    X_test.to_csv(f'{base_path}_X_test.csv', index=False)\n",
    "    y_train.to_csv(f'{base_path}_y_train.csv', index=False)\n",
    "    y_test.to_csv(f'{base_path}_y_test.csv', index=False)\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Training: {X_train.shape[0]} samples\")\n",
    "    print(f\"Testing: {X_test.shape[0]} samples\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "print(\"Performing and saving train-test splits...\")\n",
    "\n",
    "# Mathematics splits\n",
    "X_train_mat_f, X_test_mat_f, y_train_mat_f, y_test_mat_f = split_save_and_print(PmatFemale, \"Mathematics Female\")\n",
    "X_train_mat_m, X_test_mat_m, y_train_mat_m, y_test_mat_m = split_save_and_print(PmatMale, \"Mathematics Male\")\n",
    "\n",
    "# Portuguese splits\n",
    "X_train_por_f, X_test_por_f, y_train_por_f, y_test_por_f = split_save_and_print(PporFemale, \"Portuguese Female\")\n",
    "X_train_por_m, X_test_por_m, y_train_por_m, y_test_por_m = split_save_and_print(PporMale, \"Portuguese Male\")\n",
    "\n",
    "print(\"\\nAll splits have been saved to the processed_data folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
